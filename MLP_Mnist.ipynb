{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package which we will use to programing\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if you have\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print (\"MPS device is available. Successfully initiated:\")\n",
    "    print (x)\n",
    "    device = mps_device\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU is available.\")\n",
    "    print(\"GPU device count:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device:\", torch.cuda.current_device())\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Use device:\",device)\n",
    "\n",
    "# set random seed\n",
    "SEED = int(time.time())\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# multiprocessing.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "\n",
    "    ##############################################################################\n",
    "    #                    TODO: Write the transform functions                     #\n",
    "    ##############################################################################\n",
    "\n",
    "    ##### Try to apply the augmentation functions\n",
    "    # transforms.Resize((5,24)),\n",
    "\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    ##############################################################################\n",
    "    #                    TODO: Write the normalized functions                    #\n",
    "    ##############################################################################\n",
    "\n",
    "    ##### Try to apply the normalized functions\n",
    "    transforms.Normalize(0.485, 0.229)\n",
    "\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################\n",
    "\n",
    "    ])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    ##############################################################################\n",
    "    #                    TODO: Write the normalized functions                    #\n",
    "    ##############################################################################\n",
    "\n",
    "    ##### Try to apply the normalized functions\n",
    "    transforms.Normalize(0.485, 0.229)\n",
    "\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST(root='./Data', train=True, download=True, transform=train_transform)\n",
    "test_set = datasets.FashionMNIST(root='./Data', train=False, download=True, transform=valid_transform)\n",
    "\n",
    "print('Number of total training dataset:', len(trainset))\n",
    "print('Number of testing dataset:', len(test_set))\n",
    "\n",
    "length = len(trainset)\n",
    "n_TrainData = math.floor(length * 0.8)\n",
    "n_ValidData = length - n_TrainData\n",
    "print('Number of training data : ',n_TrainData)\n",
    "print('Number of validation data : ', n_ValidData)\n",
    "\n",
    "train_set, valid_set = torch.utils.data.random_split(\n",
    "    trainset,\n",
    "    [n_TrainData, n_ValidData],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")\n",
    "\n",
    "\n",
    "class_num = 10\n",
    "classes = ('T-shirt/top', ' Trouser', ' Pullover', ' Dress',\n",
    "           ' Coat', ' Sandal', ' Shirt', ' Sneaker', ' Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded Datasets to DataLoaders\n",
    "\n",
    "##############################################################################\n",
    "#                    TODO: Validation Dataloader                             #\n",
    "##############################################################################\n",
    "\n",
    "# please change the batch_size\n",
    "trainloader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers = 0)\n",
    "validloader = DataLoader(valid_set, batch_size=128, shuffle=False, num_workers = 0)\n",
    "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers = 0)\n",
    "\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Build your model here!\n",
    "#\n",
    "# Practice:\n",
    "#   Try to implement MLP with pytorch !\n",
    "##############################################\n",
    "\n",
    "class trainmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(trainmodel, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.feat_classifier = nn.Sequential(\n",
    "\n",
    "            ##############################################################################\n",
    "            #                    TODO: Complete the code                                 #\n",
    "            ##############################################################################\n",
    "\n",
    "            nn.Linear(in_features=16*5*5, out_features=224),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=224, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "            ##############################################################################\n",
    "            #                              END OF YOUR CODE                              #\n",
    "            ##############################################################################\n",
    "\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ##############################################################################\n",
    "        #                    TODO: Complete the code.                                #\n",
    "        ##############################################################################\n",
    "\n",
    "        # The shape of flatten output should be height * width * channel\n",
    "        # x = x.view(-1, height * width * channel)\n",
    "\n",
    "        x = self.conv_block(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = x.to(device)\n",
    "        # print(x.shape)\n",
    "        ##############################################################################\n",
    "        #                              END OF YOUR CODE                              #\n",
    "        ##############################################################################\n",
    "\n",
    "        out = self.feat_classifier(x)\n",
    "        return out\n",
    "\n",
    "model = trainmodel()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,28,28).to(device)\n",
    "x = x.to(device)\n",
    "out = model.conv_block(x)\n",
    "# flat = model.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                          TODO: Fill the parameters                         #\n",
    "##############################################################################\n",
    "\n",
    "batch_size = 64\n",
    "channel = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "\n",
    "result = model(torch.rand((batch_size, channel, height, width)).to(device))\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use GPU\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "##############################################################################\n",
    "#                         TODO: Design the Parameters                        #\n",
    "##############################################################################\n",
    "\n",
    "learning_rate = 0.0002\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 20\n",
    "\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH = './weight/model_weight_1.pth'\n",
    "checkpoint = torch.load(WEIGHT_PATH , map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "# Specify the saving path\n",
    "SAVING_PATH = './weight/'\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, epochs+1):# loop over the dataset multiple times\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    print('running epoch: {}'.format(epoch))\n",
    "\n",
    "    # train the model\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for data, target in tqdm(trainloader):\n",
    "      # move tensors to GPU if CUDA is available\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      # clear the gradients of all optimized variables\n",
    "      optimizer.zero_grad()\n",
    "      # forward pass: compute predicted outputs by passing inputs to the model\n",
    "      output = model(data)\n",
    "      # calculate the batch loss\n",
    "      loss = criterion(output, target)\n",
    "      # backward pass: compute gradient of the loss with respect to model parameters\n",
    "      loss.backward()\n",
    "      # perform a single optimization step (parameter update)\n",
    "      optimizer.step()\n",
    "      # update training loss\n",
    "      train_loss += loss.item()*data.size(0)\n",
    "      # update training Accuracy\n",
    "      train_total += target.size(0)\n",
    "      _, predicted = torch.max(output.data, 1)\n",
    "      train_correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "    # validate the model\n",
    "    model.eval()\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    for data, target in tqdm(validloader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        target = target.long()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # update validation Accuracy\n",
    "        valid_total += target.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_correct += (predicted == target).sum().item()\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Training Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(train_loss,(100 * train_correct / train_total)))\n",
    "    print('Validation Loss: {:.6f} \\tValidation Accuracy: {:.6f}'.format(valid_loss,(100 * valid_correct / valid_total)))\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(100 * train_correct / train_total)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_acc_list.append(100 * valid_correct / valid_total)\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), SAVING_PATH+'/model_weight_1.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_loss_acc(list_to_draw,name):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    if name==\"train_loss\":\n",
    "      ax1.set_title('Train Loss')\n",
    "      ax1.plot(list_to_draw)\n",
    "    elif name==\"train_acc\":\n",
    "      ax1.set_title('Train Accuracy')\n",
    "      ax1.plot(list_to_draw)\n",
    "    elif name==\"valid_loss\":\n",
    "      ax1.set_title('Valid Loss')\n",
    "      ax1.plot(list_to_draw)\n",
    "    elif name==\"valid_acc\":\n",
    "      ax1.set_title('Valid Accuracy')\n",
    "      ax1.plot(list_to_draw)\n",
    "\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_loss_acc(train_loss_list, \"train_loss\")\n",
    "plt_loss_acc(train_acc_list, \"train_acc\")\n",
    "plt_loss_acc(valid_loss_list, \"valid_loss\")\n",
    "plt_loss_acc(valid_acc_list, \"valid_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
