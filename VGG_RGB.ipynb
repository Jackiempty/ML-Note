{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('./Data/noodles/')\n",
    "print(os.listdir(DATA_PATH))\n",
    "\n",
    "# use gpu if you have\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (\"MPS device is available. Successfully initiated:\")\n",
    "    print (x)\n",
    "    device = mps_device\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU is available.\")\n",
    "    print(\"GPU device count:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device:\", torch.cuda.current_device())\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Use device:\",device)\n",
    "\n",
    "# set random seed\n",
    "SEED = int(time.time())\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "multiprocessing.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15,expand = True),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the training folder.\n",
    "TRAINDATA_PATH = os.path.join('.', 'Data','noodles','train')\n",
    "# print(TRAINDATA_PATH)\n",
    "label_name = {\"0_spaghetti\": 0, \"1_ramen\": 1, \"2_udon\": 2}\n",
    "\n",
    "def get_img_info(data_dir):\n",
    "        imgpath = []\n",
    "        imglabel = []\n",
    "        for root, dirs, _ in os.walk(data_dir):\n",
    "            # print(\"root: \", root)\n",
    "            # print(\"dirs: \", dirs)\n",
    "            # Traverse categories\n",
    "            for sub_dir in dirs:\n",
    "                img_names = os.listdir(os.path.join(root, sub_dir))\n",
    "                img_names = list(filter(lambda x: x.endswith('.jpg'), img_names))\n",
    "\n",
    "                # Traverse images\n",
    "                for i in range(len(img_names)):\n",
    "                    img_name = img_names[i]\n",
    "                    path_img = os.path.join(root, sub_dir, img_name)\n",
    "                    label = label_name[sub_dir]\n",
    "                    imgpath.append(path_img)\n",
    "                    imglabel.append(int(label))\n",
    "\n",
    "        # Return image paths and labels in data_info\n",
    "        return imgpath,  imglabel\n",
    "\n",
    "imgpath,  imglabel = get_img_info(TRAINDATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self,trainData,trainLabel,transform=None):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        self.images = trainData\n",
    "        self.label = trainLabel\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        imgpath = self.images[index]\n",
    "        img = Image.open(imgpath).convert('RGB')\n",
    "\n",
    "        label = self.label[index]\n",
    "        if self.transform:\n",
    "          img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # --------------------------------------------\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilt the train and valid data\n",
    "train_img, val_img, train_label, val_label = train_test_split(imgpath, imglabel, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set = Custom_dataset(train_img, train_label, transform=train_transform)\n",
    "valid_set = Custom_dataset(val_img, val_label, transform=valid_transform)\n",
    "\n",
    "print('Number of total training data:', len(train_set))\n",
    "print('Number of total validation data:', len(valid_set))\n",
    "\n",
    "class_num = 3\n",
    "classes = (\"spaghetti\", \"ramen\", \"udon\")\n",
    "\n",
    "# Loaded Datasets to DataLoaders\n",
    "# please change the batch_size\n",
    "trainloader = DataLoader(train_set, batch_size=16 , shuffle=True, num_workers = 0)\n",
    "validloader = DataLoader(valid_set, batch_size=16 , shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in trainloader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "for img,labels in trainloader:\n",
    "    # load a batch from train data\n",
    "    break\n",
    "\n",
    "# this converts it from GPU to CPU and selects first image\n",
    "img = img.cpu().numpy()[0]\n",
    "#convert image back to Height,Width,Channels\n",
    "img = np.transpose(img, (1,2,0))\n",
    "#show the image\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "for images, labels in validloader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "for img_test,labels in validloader:\n",
    "    # load a batch from train data\n",
    "    break\n",
    "\n",
    "# this converts it from GPU to CPU and selects first image\n",
    "img_test = img_test.cpu().numpy()[0]\n",
    "#convert image back to Height,Width,Channels\n",
    "img_test = np.transpose(img_test, (1,2,0))\n",
    "#show the image\n",
    "plt.imshow(img_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Build your model here!\n",
    "#\n",
    "# Practice:\n",
    "#   Try to implement VGG-16 with pytorch !\n",
    "##############################################\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        ##############################################################################\n",
    "        #                          TODO: implement VGG-16.                           #\n",
    "        ##############################################################################\n",
    "        self.conv_block = nn.Sequential(\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(3,  64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            # nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "        self.feat_classifier = nn.Sequential(\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.Dropout(0, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(0, 2),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            \n",
    "            nn.Linear(128, class_num),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.feat_classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG16()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"device: \",device)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 50\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH = 'Saving_Path/model_weight.pth'\n",
    "checkpoint = torch.load(WEIGHT_PATH , map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "# Specify the saving weight path\n",
    "SAVING_PATH = './Saving_Path'\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, epochs+1):# loop over the dataset multiple times\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    print('running epoch: {}'.format(epoch))\n",
    "\n",
    "    # train the model\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for data, target in tqdm(trainloader):\n",
    "      # move tensors to GPU if CUDA is available\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      # clear the gradients of all optimized variables\n",
    "      optimizer.zero_grad()\n",
    "      # forward pass: compute predicted outputs by passing inputs to the model\n",
    "      output = model(data)\n",
    "      # calculate the batch loss\n",
    "      loss = criterion(output, target)\n",
    "      # backward pass: compute gradient of the loss with respect to model parameters\n",
    "      loss.backward()\n",
    "      # perform a single optimization step (parameter update)\n",
    "      optimizer.step()\n",
    "      # update training loss\n",
    "      train_loss += loss.item()*data.size(0)\n",
    "      # update training Accuracy\n",
    "      train_total += target.size(0)\n",
    "      _, predicted = torch.max(output.data, 1)\n",
    "      train_correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "    # validate the model\n",
    "    model.eval()\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    for data, target in tqdm(validloader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        target = target.long()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # update validation Accuracy\n",
    "        valid_total += target.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_correct += (predicted == target).sum().item()\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Training Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(train_loss,(100 * train_correct / train_total)))\n",
    "    print('Validation Loss: {:.6f} \\tValidation Accuracy: {:.6f}'.format(valid_loss,(100 * valid_correct / valid_total)))\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(100 * train_correct / train_total)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_acc_list.append(100 * valid_correct / valid_total)\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), SAVING_PATH+'/model_weight.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_acc_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All acc')\n",
    "\n",
    "    ax1.plot(train_acc_list)\n",
    "    ax1.plot(valid_acc_list)\n",
    "\n",
    "    ax1.legend(['train_acc', 'valid_acc'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plt_loss_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All loss')\n",
    "\n",
    "    ax1.plot(train_loss_list)\n",
    "    ax1.plot(valid_loss_list)\n",
    "\n",
    "    ax1.legend(['train_loss', 'valid_loss'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_loss_all()\n",
    "plt_acc_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted[0].item())\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as data_utils\n",
    "TESTDATA_PATH = './Data/noodles/test/unknown'\n",
    "for data in os.walk(TESTDATA_PATH):\n",
    "  test_data=data[2]\n",
    "test_transform = transforms.Compose([\n",
    "\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485,0.456,0.406],\n",
    "        std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "class Custom_testset(Dataset):\n",
    "    def __init__(self,testData,transform=None):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        self.images = testData\n",
    "        #self.label = trainLabel\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        imgpath = self.images[index]\n",
    "        img = Image.open(imgpath).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "          img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # --------------------------------------------\n",
    "        return len(self.images)\n",
    "\n",
    "def trueclass(num):\n",
    "  if num==0:\n",
    "    return 0\n",
    "  elif num==1:\n",
    "    return 1\n",
    "  elif num==2:\n",
    "    return 2\n",
    "\n",
    "imgpath=[]\n",
    "prediction=[]\n",
    "for photo in test_data:\n",
    "  path_img = os.path.join(TESTDATA_PATH,photo)\n",
    "  imgpath.append(path_img)\n",
    "# print('id = ',test_data)\n",
    "test_set = Custom_testset(imgpath,test_transform)\n",
    "testloader = DataLoader(test_set, batch_size=1 , shuffle=False, num_workers = 0)\n",
    "for images in testloader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    break\n",
    "\n",
    "#images = np.transpose(images, (1,2,0))\n",
    "for images in testloader:\n",
    "  #print('image = ',images)\n",
    "  images=images.to(device)\n",
    "  output = model(images)\n",
    "  predicted = torch.argmax(output,dim=1)\n",
    "  #print('Image predicted label = :', predicted.item())\n",
    "  prediction=np.append(prediction,trueclass(predicted.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lst=prediction.tolist()\n",
    "for i in range(len(prediction_lst)):\n",
    "  prediction_lst[i] = int(prediction_lst[i])\n",
    "test_data_num=[]\n",
    "for i in range(len(test_data)):\n",
    "  test_data_num.append(i)\n",
    "\n",
    "example={'ID':test_data_num,\n",
    "      'Target':prediction_lst}\n",
    "df = pd.DataFrame(example)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('./result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
