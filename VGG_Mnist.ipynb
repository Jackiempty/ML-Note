{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package which we will use to programing\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if you have\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print (\"MPS device is available. Successfully initiated:\")\n",
    "    print (x)\n",
    "    device = mps_device\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU is available.\")\n",
    "    print(\"GPU device count:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device:\", torch.cuda.current_device())\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Use device:\",device)\n",
    "\n",
    "# set random seed\n",
    "SEED = int(time.time())\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# multiprocessing.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.485, 0.229)\n",
    "    ])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.485, 0.229)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root='./Data', train=True, download=True, transform=train_transform)\n",
    "test_set = datasets.MNIST(root='./Data', train=False, download=True, transform=valid_transform)\n",
    "\n",
    "print('Number of total training dataset:', len(trainset))\n",
    "print('Number of testing dataset:', len(test_set))\n",
    "\n",
    "length = len(trainset)\n",
    "n_TrainData = math.floor(length * 0.8)\n",
    "n_ValidData = length - n_TrainData\n",
    "print('Number of training data : ',n_TrainData)\n",
    "print('Number of validation data : ', n_ValidData)\n",
    "\n",
    "train_set, valid_set = torch.utils.data.random_split(\n",
    "    trainset,\n",
    "    [n_TrainData, n_ValidData],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")\n",
    "\n",
    "\n",
    "class_num = 10\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded Datasets to DataLoaders\n",
    "\n",
    "##############################################################################\n",
    "#                    TODO: Validation Dataloader                             #\n",
    "##############################################################################\n",
    "\n",
    "# please change the batch_size\n",
    "trainloader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers = 0)\n",
    "validloader = DataLoader(valid_set, batch_size=32, shuffle=False, num_workers = 0)\n",
    "testloader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers = 0)\n",
    "\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Build your model here!\n",
    "#\n",
    "# Practice:\n",
    "#   Try to implement VGG-16 with pytorch !\n",
    "##############################################\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        ##############################################################################\n",
    "        #                          TODO: implement VGG-16.                           #\n",
    "        ##############################################################################\n",
    "        self.conv_block = nn.Sequential(\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(in_channels=1,  out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "        self.feat_classifier = nn.Sequential(\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.Dropout(0, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = x.to(device)\n",
    "        x = self.feat_classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG16()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use GPU\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "##############################################################################\n",
    "#                         TODO: Design the Parameters                        #\n",
    "##############################################################################\n",
    "\n",
    "learning_rate = 0.0002\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 20\n",
    "\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH = './weight/model_weight_2.pth'\n",
    "checkpoint = torch.load(WEIGHT_PATH , map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "# Specify the saving path\n",
    "SAVING_PATH = './weight/'\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, epochs+1):# loop over the dataset multiple times\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    print('running epoch: {}'.format(epoch))\n",
    "\n",
    "    # train the model\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for data, target in tqdm(trainloader):\n",
    "      # move tensors to GPU if CUDA is available\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      # clear the gradients of all optimized variables\n",
    "      optimizer.zero_grad()\n",
    "      # forward pass: compute predicted outputs by passing inputs to the model\n",
    "      output = model(data)\n",
    "      # calculate the batch loss\n",
    "      loss = criterion(output, target)\n",
    "      # backward pass: compute gradient of the loss with respect to model parameters\n",
    "      loss.backward()\n",
    "      # perform a single optimization step (parameter update)\n",
    "      optimizer.step()\n",
    "      # update training loss\n",
    "      train_loss += loss.item()*data.size(0)\n",
    "      # update training Accuracy\n",
    "      train_total += target.size(0)\n",
    "      _, predicted = torch.max(output.data, 1)\n",
    "      train_correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "    # validate the model\n",
    "    model.eval()\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    for data, target in tqdm(validloader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        target = target.long()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # update validation Accuracy\n",
    "        valid_total += target.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_correct += (predicted == target).sum().item()\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Training Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(train_loss,(100 * train_correct / train_total)))\n",
    "    print('Validation Loss: {:.6f} \\tValidation Accuracy: {:.6f}'.format(valid_loss,(100 * valid_correct / valid_total)))\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(100 * train_correct / train_total)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_acc_list.append(100 * valid_correct / valid_total)\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), SAVING_PATH+'/model_weight_2.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_acc_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All acc')\n",
    "\n",
    "    ax1.plot(train_acc_list)\n",
    "    ax1.plot(valid_acc_list)\n",
    "\n",
    "    ax1.legend(['train_acc', 'valid_acc'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plt_loss_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All loss')\n",
    "\n",
    "    ax1.plot(train_loss_list)\n",
    "    ax1.plot(valid_loss_list)\n",
    "\n",
    "    ax1.legend(['train_loss', 'valid_loss'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_loss_all()\n",
    "plt_acc_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
